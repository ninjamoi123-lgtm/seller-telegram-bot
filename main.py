import os
import re
import csv
import sqlite3
from datetime import datetime
from pathlib import Path

import pandas as pd

from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters


# ========= –ù–ê–°–¢–†–û–ô–ö–ò =========
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
DB_PATH = os.getenv("DB_PATH", "bot.db")
TMP_DIR = Path(os.getenv("TMP_DIR", "/tmp"))

if not TELEGRAM_BOT_TOKEN:
    raise RuntimeError("–ù–µ—Ç TELEGRAM_BOT_TOKEN. –î–æ–±–∞–≤—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

TMP_DIR.mkdir(parents=True, exist_ok=True)


# ========= –ö–ù–û–ü–ö–ò (–∫–∞–∫ —Ç—ã —Ö–æ—Ç–µ–ª: 1 –∫–Ω–æ–ø–∫–∞ = 1 —Å—Ç—Ä–æ–∫–∞) =========
MAIN_KB = ReplyKeyboardMarkup(
    keyboard=[
        ["üìà –ü—Ä–∏–±—ã–ª—å –∑–∞ –ø–µ—Ä–∏–æ–¥"],
        ["üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (SKU ‚Üí ‚ÇΩ)"],
        ["‚¨ÖÔ∏è –í –º–µ–Ω—é"],
    ],
    resize_keyboard=True
)

MODE_KB = ReplyKeyboardMarkup(
    keyboard=[
        ["üü° –î–µ–Ω—å–≥–∏ –æ—Ç OZON"],
        ["üü¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å"],
        ["‚¨ÖÔ∏è –í –º–µ–Ω—é"],
    ],
    resize_keyboard=True
)


# ========= –ë–ê–ó–ê SQLITE =========
def db():
    return sqlite3.connect(DB_PATH)

def init_db():
    with db() as conn:
        conn.execute("""
        CREATE TABLE IF NOT EXISTS cogs (
            tg_id INTEGER NOT NULL,
            sku TEXT NOT NULL,
            cogs REAL NOT NULL,
            updated_at TEXT NOT NULL,
            PRIMARY KEY (tg_id, sku)
        )
        """)
        conn.execute("""
        CREATE TABLE IF NOT EXISTS profit_reports (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            tg_id INTEGER NOT NULL,
            mode TEXT NOT NULL,
            file_name TEXT NOT NULL,
            revenue REAL NOT NULL,
            deductions REAL NOT NULL,
            net_mp REAL NOT NULL,
            cogs_total REAL,
            net_profit REAL,
            margin REAL,
            created_at TEXT NOT NULL,
            note TEXT
        )
        """)

def upsert_cogs(tg_id: int, sku: str, cogs_val: float):
    with db() as conn:
        conn.execute(
            "INSERT INTO cogs(tg_id, sku, cogs, updated_at) VALUES(?,?,?,?) "
            "ON CONFLICT(tg_id, sku) DO UPDATE SET cogs=excluded.cogs, updated_at=excluded.updated_at",
            (tg_id, sku, float(cogs_val), datetime.utcnow().strftime("%Y-%m-%d"))
        )

def get_cogs_map(tg_id: int) -> dict:
    with db() as conn:
        rows = conn.execute("SELECT sku, cogs FROM cogs WHERE tg_id=?", (tg_id,)).fetchall()
    return {r[0]: float(r[1]) for r in rows}

def save_report(tg_id: int, payload: dict):
    with db() as conn:
        conn.execute("""
        INSERT INTO profit_reports(
            tg_id, mode, file_name, revenue, deductions, net_mp,
            cogs_total, net_profit, margin, created_at, note
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?)
        """, (
            tg_id,
            payload["mode"],
            payload["file_name"],
            float(payload["revenue"]),
            float(payload["deductions"]),
            float(payload["net_mp"]),
            payload.get("cogs_total"),
            payload.get("net_profit"),
            payload.get("margin"),
            datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            payload.get("note", ""),
        ))


# ========= –£–¢–ò–õ–ò–¢–´ =========
def money(x: float) -> str:
    if abs(x - int(x)) < 1e-9:
        return f"{int(x)} ‚ÇΩ"
    return f"{x:.2f} ‚ÇΩ"

def pct(x: float) -> str:
    return f"{x:.2f}%"

def _norm(s: str) -> str:
    return re.sub(r"\s+", " ", str(s)).strip().lower()

def _parse_number(x):
    if pd.isna(x):
        return None
    s = str(x).replace("\u00A0", "").replace(" ", "").replace(",", ".").strip()
    m = re.search(r"-?\d+(?:\.\d+)?", s)
    if not m:
        return None
    try:
        return float(m.group(0))
    except Exception:
        return None


# ========= –ß–¢–ï–ù–ò–ï –û–¢–ß–Å–¢–ê (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ) =========
def load_table(file_path: str) -> pd.DataFrame:
    p = Path(file_path)
    if p.suffix.lower() in (".xlsx", ".xls"):
        return pd.read_excel(file_path, engine="openpyxl")

    # csv
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        sample = f.read(4096)
    sep = ";" if sample.count(";") > sample.count(",") else ","
    return pd.read_csv(file_path, sep=sep, engine="python")

def find_amount_col(cols: list[str]) -> str | None:
    # —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º "–ò—Ç–æ–≥–æ" (—Å–∞–º—ã–π –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)
    for c in cols:
        nc = _norm(c)
        if "–∏—Ç–æ–≥–æ" in nc:
            return c

    # –ø–æ—Ç–æ–º –ª—é–±—ã–µ —Å—É–º–º—ã/–Ω–∞—á–∏—Å–ª–µ–Ω–∏—è
    for c in cols:
        nc = _norm(c)
        if ("—Å—É–º–º" in nc) or ("–Ω–∞—á–∏—Å–ª" in nc) or ("amount" in nc):
            return c

    return None

def find_sku_col(cols: list[str]) -> str | None:
    keys = ["sku", "offer", "–∞—Ä—Ç–∏–∫—É–ª"]
    for c in cols:
        nc = _norm(c)
        if any(k in nc for k in keys):
            return c
    return None

def find_qty_col(cols: list[str]) -> str | None:
    keys = ["–∫–æ–ª", "quantity", "qty"]
    for c in cols:
        nc = _norm(c)
        if any(k in nc for k in keys):
            return c
    return None

def parse_report(file_path: str) -> dict:
    df = load_table(file_path)
    if df.empty:
        raise ValueError("–§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è.")

    df.columns = [str(c).strip() for c in df.columns]
    cols = list(df.columns)

    amount_col = find_amount_col(cols)
    if not amount_col:
        # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –≤—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º —á–∏—Å–µ–ª
        best, best_score = None, 0
        for c in cols:
            score = df[c].map(_parse_number).notna().sum()
            if score > best_score:
                best_score, best = score, c
        amount_col = best

    if not amount_col:
        raise ValueError("–ù–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É —Å —Å—É–º–º–æ–π/–∏—Ç–æ–≥–æ –≤ –æ—Ç—á—ë—Ç–µ.")

    sku_col = find_sku_col(cols)
    qty_col = find_qty_col(cols)

    df["_amount"] = df[amount_col].map(_parse_number)
    df = df[df["_amount"].notna()].copy()

    if sku_col:
        df["_sku"] = df[sku_col].astype(str).str.strip()
    else:
        df["_sku"] = ""

    if qty_col:
        df["_qty"] = df[qty_col].map(_parse_number).fillna(1).astype(float)
        df.loc[df["_qty"] <= 0, "_qty"] = 1.0
    else:
        df["_qty"] = 1.0

    total = float(df["_amount"].sum())
    revenue = float(df.loc[df["_amount"] > 0, "_amount"].sum())
    deductions = float(df.loc[df["_amount"] < 0, "_amount"].sum())

    by_sku_amount = None
    if sku_col:
        by_sku_amount = df.groupby("_sku")["_amount"].sum().sort_values(ascending=False)

    note = f"amount_col={amount_col} | sku_col={sku_col or 'NOT_FOUND'} | qty_col={qty_col or 'NOT_FOUND'}"
    return {"df": df, "total": total, "revenue": revenue, "deductions": deductions, "by_sku_amount": by_sku_amount, "note": note}

def top_lines(series: pd.Series | None, n: int = 5, ascending: bool = False) -> str:
    if series is None or series.empty:
        return "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    s = series.sort_values(ascending=ascending).head(n)
    out = []
    for k, v in s.items():
        out.append(f"{k} ‚Äî {money(float(v))}")
    return "\n".join(out)


# ========= BOT =========
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data.clear()
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç üëã\n\n"
        "–Ø —Å—á–∏—Ç–∞—é –ø—Ä–∏–±—ã–ª—å –ø–æ –æ—Ç—á—ë—Ç—É OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª.\n"
        "–ü–µ—Ä–∏–æ–¥ —Ç—ã –≤—ã–±–∏—Ä–∞–µ—à—å –≤ –∫–∞–±–∏–Ω–µ—Ç–µ OZON —Å–∞–º, –ø–æ—Ç–æ–º –∑–∞–≥—Ä—É–∂–∞–µ—à—å —Ñ–∞–π–ª —Å—é–¥–∞.\n\n"
        "–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ ‚¨áÔ∏è",
        reply_markup=MAIN_KB
    )

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()

    if text == "‚¨ÖÔ∏è –í –º–µ–Ω—é":
        context.user_data.clear()
        await update.message.reply_text("–ú–µ–Ω—é ‚¨áÔ∏è", reply_markup=MAIN_KB)
        return

    if text == "üìà –ü—Ä–∏–±—ã–ª—å –∑–∞ –ø–µ—Ä–∏–æ–¥":
        context.user_data.clear()
        await update.message.reply_text(
            "–ö–∞–∫ —Å—á–∏—Ç–∞—Ç—å?\n\n"
            "üü° –î–µ–Ω—å–≥–∏ –æ—Ç OZON ‚Äî –∏—Ç–æ–≥ –ø–æ –æ—Ç—á—ë—Ç—É (–≤ –ø–ª—é—Å–µ/–≤ –º–∏–Ω—É—Å–µ)\n"
            "üü¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å ‚Äî –Ω—É–∂–Ω–∞ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å SKU ‚Üí ‚ÇΩ\n\n"
            "–í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º ‚¨áÔ∏è",
            reply_markup=MODE_KB
        )
        return

    if text == "üü° –î–µ–Ω—å–≥–∏ –æ—Ç OZON":
        context.user_data.clear()
        context.user_data["mode"] = "mp_money"
        context.user_data["await_report"] = True
        await update.message.reply_text(
            "–û–∫. –ü—Ä–∏—à–ª–∏ —Ñ–∞–π–ª–æ–º –æ—Ç—á—ë—Ç OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª –∑–∞ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n"
            "–§–æ—Ä–º–∞—Ç: .xlsx –∏–ª–∏ .csv",
            reply_markup=MODE_KB
        )
        return

    if text == "üü¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å":
        context.user_data.clear()
        context.user_data["mode"] = "net_profit"
        context.user_data["await_report"] = True
        await update.message.reply_text(
            "–û–∫. –ü—Ä–∏—à–ª–∏ —Ñ–∞–π–ª–æ–º –æ—Ç—á—ë—Ç OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª –∑–∞ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n"
            "–§–æ—Ä–º–∞—Ç: .xlsx –∏–ª–∏ .csv\n\n"
            "–ï—Å–ª–∏ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–∞–ª ‚Äî —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏ —á–µ—Ä–µ–∑ ¬´üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (SKU ‚Üí ‚ÇΩ)¬ª.",
            reply_markup=MODE_KB
        )
        return

    if text == "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (SKU ‚Üí ‚ÇΩ)":
        context.user_data.clear()
        context.user_data["await_cogs"] = True
        await update.message.reply_text(
            "–ü—Ä–∏—à–ª–∏ CSV —Ñ–∞–π–ª —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n\n"
            "sku,cogs\n"
            "ABC-123,380\n"
            "XYZ-777,1250\n\n"
            "–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å ',' –∏–ª–∏ ';'.",
            reply_markup=BACK_TO_MENU_KB
        )
        return

    # –µ—Å–ª–∏ –∂–¥—ë–º —Ñ–∞–π–ª
    if context.user_data.get("await_report"):
        await update.message.reply_text("–ñ–¥—É —Ñ–∞–π–ª –æ—Ç—á—ë—Ç–∞ (.xlsx –∏–ª–∏ .csv). –ü—Ä–∏—à–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–º.", reply_markup=MODE_KB)
        return
    if context.user_data.get("await_cogs"):
        await update.message.reply_text("–ñ–¥—É CSV —Ñ–∞–π–ª —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ (sku,cogs).", reply_markup=BACK_TO_MENU_KB)
        return

    await update.message.reply_text("–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ –∫–Ω–æ–ø–∫–æ–π ‚¨áÔ∏è", reply_markup=MAIN_KB)

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    doc = update.message.document
    tg_id = update.effective_user.id
    if not doc:
        return

    file_name = doc.file_name or "file"
    suffix = Path(file_name).suffix.lower()

    tg_file = await context.bot.get_file(doc.file_id)

    # --- —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å ---
    if context.user_data.get("await_cogs"):
        if suffix != ".csv":
            await update.message.reply_text("–ù—É–∂–µ–Ω CSV —Ñ–∞–π–ª (.csv).", reply_markup=BACK_TO_MENU_KB)
            return

        local_path = str(TMP_DIR / f"cogs_{tg_id}_{int(datetime.utcnow().timestamp())}.csv")
        await tg_file.download_to_drive(custom_path=local_path)

        try:
            with open(local_path, "r", encoding="utf-8", errors="ignore") as f:
                sample = f.read(4096)
            delim = ";" if sample.count(";") > sample.count(",") else ","

            count = 0
            with open(local_path, "r", encoding="utf-8", errors="ignore", newline="") as f:
                reader = csv.DictReader(f, delimiter=delim)
                if not reader.fieldnames:
                    raise ValueError("–ù–µ –≤–∏–∂—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤. –ù—É–∂–Ω—ã sku –∏ cogs.")

                # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                fields = {_norm(x): x for x in reader.fieldnames}
                if "sku" not in fields or "cogs" not in fields:
                    raise ValueError("–ù—É–∂–Ω—ã –∫–æ–ª–æ–Ω–∫–∏: sku,cogs")

                sku_key = fields["sku"]
                cogs_key = fields["cogs"]

                for row in reader:
                    sku = (row.get(sku_key) or "").strip()
                    cogs_raw = row.get(cogs_key)
                    if not sku:
                        continue
                    cogs_val = _parse_number(cogs_raw)
                    if cogs_val is None:
                        continue
                    upsert_cogs(tg_id, sku, float(cogs_val))
                    count += 1

            context.user_data.clear()
            await update.message.reply_text(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–µ–π: {count} SKU", reply_markup=MAIN_KB)

        except Exception as e:
            await update.message.reply_text(f"–û—à–∏–±–∫–∞ CSV: {e}", reply_markup=BACK_TO_MENU_KB)
        return

    # --- –æ—Ç—á—ë—Ç ---
    if context.user_data.get("await_report"):
        if suffix not in (".xlsx", ".xls", ".csv"):
            await update.message.reply_text("–ù—É–∂–µ–Ω —Ñ–∞–π–ª .xlsx –∏–ª–∏ .csv", reply_markup=MODE_KB)
            return

        local_path = str(TMP_DIR / f"report_{tg_id}_{int(datetime.utcnow().timestamp())}{suffix}")
        await tg_file.download_to_drive(custom_path=local_path)

        mode = context.user_data.get("mode", "mp_money")

        try:
            parsed = parse_report(local_path)
            revenue = parsed["revenue"]
            deductions = parsed["deductions"]
            net_mp = parsed["total"]

            # üü° —Ä–µ–∂–∏–º
            if mode == "mp_money":
                status = "üü¢" if net_mp > 0 else "üî¥"
                msg = (
                    "üìà –ò—Ç–æ–≥–∏ –ø–æ –æ—Ç—á—ë—Ç—É OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª\n\n"
                    f"–ù–∞—á–∏—Å–ª–µ–Ω–æ (–ø–ª—é—Å): {money(revenue)}\n"
                    f"–£–¥–µ—Ä–∂–∞–Ω–∏—è (–º–∏–Ω—É—Å): {money(deductions)}\n"
                    f"–ò—Ç–æ–≥–æ –æ—Ç OZON: {money(net_mp)}\n"
                    f"–°—Ç–∞—Ç—É—Å: {status}\n\n"
                )

                if parsed["by_sku_amount"] is not None and not parsed["by_sku_amount"].empty:
                    msg += "–¢–û–ü-5 SKU –ø–æ –∏—Ç–æ–≥—É:\n" + top_lines(parsed["by_sku_amount"], 5, ascending=False) + "\n\n"
                    msg += "–¢–û–ü-5 SKU –≤ –º–∏–Ω—É—Å:\n" + top_lines(parsed["by_sku_amount"], 5, ascending=True) + "\n"
                else:
                    msg += "–¢–û–ü SKU: –Ω–µ—Ç (–≤ –æ—Ç—á—ë—Ç–µ –Ω–µ –Ω–∞—à—ë–ª –∫–æ–ª–æ–Ω–∫—É SKU/offer_id/–∞—Ä—Ç–∏–∫—É–ª)\n"

                save_report(tg_id, {
                    "mode": "mp_money",
                    "file_name": file_name,
                    "revenue": revenue,
                    "deductions": deductions,
                    "net_mp": net_mp,
                    "note": parsed["note"],
                })

                context.user_data.clear()
                await update.message.reply_text(msg, reply_markup=MAIN_KB)
                return

            # üü¢ —Ä–µ–∂–∏–º
            cogs_map = get_cogs_map(tg_id)
            if not cogs_map:
                status = "üü¢" if net_mp > 0 else "üî¥"
                msg = (
                    "üü¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å\n\n"
                    "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\n"
                    "–ü–æ–∫–∞–∑—ã–≤–∞—é –¥–µ–Ω—å–≥–∏ –æ—Ç OZON (–±–µ–∑ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏):\n\n"
                    f"–ò—Ç–æ–≥–æ –æ—Ç OZON: {money(net_mp)}\n"
                    f"–°—Ç–∞—Ç—É—Å: {status}\n\n"
                    "–ó–∞–≥—Ä—É–∑–∏ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å —á–µ—Ä–µ–∑ ¬´üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å (SKU ‚Üí ‚ÇΩ)¬ª –∏ –ø–æ–≤—Ç–æ—Ä–∏ —Ä–∞—Å—á—ë—Ç."
                )
                save_report(tg_id, {
                    "mode": "net_profit",
                    "file_name": file_name,
                    "revenue": revenue,
                    "deductions": deductions,
                    "net_mp": net_mp,
                    "note": "NO_COGS | " + parsed["note"],
                })
                context.user_data.clear()
                await update.message.reply_text(msg, reply_markup=MAIN_KB)
                return

            df = parsed["df"].copy()
            df = df[df["_sku"].astype(str).str.len() > 0].copy()

            if df.empty:
                msg = (
                    "üü¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å\n\n"
                    "–í –æ—Ç—á—ë—Ç–µ –Ω–µ –Ω–∞—à—ë–ª SKU/offer_id/–∞—Ä—Ç–∏–∫—É–ª ‚Äî –Ω–µ –º–æ–≥—É –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å.\n"
                    "–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —ç—Ç–æ –æ—Ç—á—ë—Ç OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª, –∏ –ø—Ä–∏—à–ª–∏ —Å–Ω–æ–≤–∞."
                )
                context.user_data.clear()
                await update.message.reply_text(msg, reply_markup=MAIN_KB)
                return

            df["_cogs"] = df["_sku"].map(lambda s: cogs_map.get(s, 0.0)).astype(float)
            df["_cogs_sum"] = df["_cogs"] * df["_qty"]

            cogs_total = float(df["_cogs_sum"].sum())
            net_profit = net_mp - cogs_total
            margin = (net_profit / revenue * 100.0) if revenue > 0 else 0.0

            status = "üî¥" if net_profit <= 0 else ("üü°" if margin < 15 else "üü¢")

            # –ø—Ä–∏–±—ã–ª—å –ø–æ sku
            amt_by_sku = df.groupby("_sku")["_amount"].sum()
            cogs_by_sku = df.groupby("_sku")["_cogs_sum"].sum()
            profit_by_sku = (amt_by_sku - cogs_by_sku)

            msg = (
                "üü¢ –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å –ø–æ –æ—Ç—á—ë—Ç—É OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª\n\n"
                f"–ò—Ç–æ–≥–æ –æ—Ç OZON: {money(net_mp)}\n"
                f"–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å: {money(cogs_total)}\n\n"
                f"–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å: {money(net_profit)}\n"
                f"–ú–∞—Ä–∂–∞: {pct(margin)}\n"
                f"–°—Ç–∞—Ç—É—Å: {status}\n\n"
                "–¢–û–ü-5 SKU –ø–æ –ø—Ä–∏–±—ã–ª–∏:\n"
                f"{top_lines(profit_by_sku, 5, ascending=False)}\n\n"
                "–¢–û–ü-5 SKU –≤ –º–∏–Ω—É—Å:\n"
                f"{top_lines(profit_by_sku, 5, ascending=True)}\n"
            )

            save_report(tg_id, {
                "mode": "net_profit",
                "file_name": file_name,
                "revenue": revenue,
                "deductions": deductions,
                "net_mp": net_mp,
                "cogs_total": cogs_total,
                "net_profit": net_profit,
                "margin": margin,
                "note": parsed["note"],
            })

            context.user_data.clear()
            await update.message.reply_text(msg, reply_markup=MAIN_KB)

        except Exception as e:
            await update.message.reply_text(
                f"–ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Ñ–∞–π–ª üòï\n\n–û—à–∏–±–∫–∞: {e}\n\n"
                "–ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —ç—Ç–æ –æ—Ç—á—ë—Ç OZON ¬´–ù–∞—á–∏—Å–ª–µ–Ω–∏—è¬ª (.xlsx/.csv) –∏ –ø—Ä–∏—à–ª–∏ —Å–Ω–æ–≤–∞.",
                reply_markup=MODE_KB
            )
        return

    # –µ—Å–ª–∏ —Ñ–∞–π–ª –ø—Ä–∏—Å–ª–∞–ª–∏ –Ω–µ –≤ —Ç–æ—Ç –º–æ–º–µ–Ω—Ç
    await update.message.reply_text("–Ø —Å–µ–π—á–∞—Å –Ω–µ –∂–¥—É —Ñ–∞–π–ª. –ù–∞–∂–º–∏ ¬´üìà –ü—Ä–∏–±—ã–ª—å –∑–∞ –ø–µ—Ä–∏–æ–¥¬ª.", reply_markup=MAIN_KB)


def main():
    init_db()
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.run_polling()


if __name__ == "__main__":
    main()
